# HuggingFace Data Pipeline with Delta Lake Integration
# Processes Japanese content from HuggingFace datasets via Delta Lake
name: "duckdb_pipeline" 
version: "2.0.0"

# This setting configures which "profile" dbt uses for this project.
profile: "duckdb_pipeline"

# Include project variables from dbt_project_vars.yml
vars:
  use_delta_lake: true
  batch_id: "{{ run_started_at.strftime('%Y%m%d_%H%M%S') }}"
  
# Additional vars from dbt_project_vars.yml will be loaded automatically

# These configurations specify where dbt should look for different types of files.
# The `model-paths` config, for example, states that models in this project can be
# found in the "models/" directory. You probably won't need to change these!
model-paths: ["models"]
analysis-paths: ["analyses"]
test-paths: ["tests"]
seed-paths: ["seeds"]
macro-paths: ["macros"]
snapshot-paths: ["snapshots"]

clean-targets: # directories to be removed by `dbt clean`
  - "target"
  - "dbt_packages"

# Configuring models
# Full documentation: https://docs.getdbt.com/docs/configuring-models

# In this example config, we tell dbt to build all models in the example/
# directory as views. These settings can be overridden in the individual model
# files using the `{{ config(...) }}` macro.
models:
  duckdb_pipeline:
    # Staging models - views for easy iteration
    staging:
      +materialized: view
      +docs:
        node_color: "#1E90FF"
    
    # Mart models - tables for performance
    marts:
      +materialized: table
      +docs:
        node_color: "#32CD32"
    
    # Legacy example models
    example:
      +materialized: view
